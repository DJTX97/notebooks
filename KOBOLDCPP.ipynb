{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title <-- Tap this if you play on Mobile { display-mode: \"form\" }\n",
    "%%html\n",
    "<b>Press play on the music player to keep the tab alive, then start KoboldCpp below</b><br/>\n",
    "<audio autoplay=\"\" src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" loop controls>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Load utils\n",
    "\n",
    "def get_renamed_file(MODEL_FILE_URL):\n",
    "    file = MODEL_FILE_URL\n",
    "    return file.split(file[file.rfind(\"/\")])[-1]\n",
    "    \n",
    "\n",
    "def get_target_repo(MODEL_ID):\n",
    "    return f\"https://huggingface.co/{MODEL_ID}/tree/main?not-for-all-audiences=true\"\n",
    "\n",
    "\n",
    "def get_target_links(MODEL_TYPE, MODEL_FILES, links):\n",
    "\n",
    "    LINKS = []\n",
    "\n",
    "    if MODEL_TYPE == \"gguf\":\n",
    "        truth_links = MODEL_FILES if len(MODEL_FILES) > 0 else links\n",
    "        LINKS = [link.replace(\"/blob/\", \"/resolve/\") for link in truth_links if link.endswith(\".gguf\") and \"/blob/\" in link]\n",
    "        return LINKS\n",
    "\n",
    "\n",
    "def create_download_file(MODEL_TYPE, LINKS, shopping_list, renamed_file):\n",
    "    with open(shopping_list, \"a\") as file:\n",
    "        if MODEL_TYPE == \"gguf\":\n",
    "            for url in LINKS:\n",
    "                file.write(f\"{url}\\n out={renamed_file}\\n\")\n",
    "        else:\n",
    "            for url in LINKS:\n",
    "                if url.endswith(\".safetensors\"):\n",
    "                    file.write(f\"{url}\\n out={renamed_file}\\n\")\n",
    "                elif url.endswith(\".model\"):\n",
    "                    file.write(f\"{url}\\n out=tokenizer.model\\n\")\n",
    "                else:\n",
    "                    file.write(f\"{url}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@Install Backend & Deps\n",
    "!apt update\n",
    "!apt install aria2 -y\n",
    "\n",
    "!echo Downloading KoboldCpp, please wait...\n",
    "!wget -O dlfile.tmp https://kcpplinux.concedo.workers.dev && mv dlfile.tmp koboldcpp_linux\n",
    "!test -f koboldcpp_linux && echo Download Successful || echo Download Failed\n",
    "!chmod +x ./koboldcpp_linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIONS = {\n",
    "    1: {\n",
    "        \"id\": \"mradermacher/Fimbulvetr-11B-v2-GGUF\",\n",
    "        \"file\": \"https://huggingface.co/mradermacher/Fimbulvetr-11B-v2-GGUF/blob/main/Fimbulvetr-11B-v2.Q5_K_S.gguf\"\n",
    "    }\n",
    "}\n",
    "\n",
    "PRESET = \"1\" #@param [1]\n",
    "\n",
    "MODEL = OPTIONS[int(PRESET)][\"file\"].replace(\"/blob/\", \"/resolve/\")\n",
    "\n",
    "!aria2c -x 10 -o model.gguf --summary-interval=5 --download-result=default --allow-overwrite=true --file-allocation=none $MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@LAUNCH!\n",
    "\n",
    "!./koboldcpp_linux model.gguf --usecublas 0 mmq --multiuser --gpulayers 60 --contextsize 4096 --quiet --remotetunnel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
