{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title <-- Tap this if you play on Mobile { display-mode: \"form\" }\n",
    "%%html\n",
    "<b>Press play on the music player to keep the tab alive, then start KoboldCpp below</b><br/>\n",
    "<audio autoplay=\"\" src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" loop controls>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install Backend & Deps\n",
    "!apt update\n",
    "!apt install aria2 -y\n",
    "\n",
    "!echo Downloading KoboldCpp, please wait...\n",
    "!wget -O dlfile.tmp https://kcpplinux.concedo.workers.dev && mv dlfile.tmp koboldcpp_linux\n",
    "!test -f koboldcpp_linux && echo Download Successful || echo Download Failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Download Model\n",
    "OPTIONS = {\n",
    "    1: {\n",
    "        \"id\": \"mradermacher/Fimbulvetr-11B-v2-GGUF\",\n",
    "        \"file\": \"https://huggingface.co/mradermacher/Fimbulvetr-11B-v2-GGUF/blob/main/Fimbulvetr-11B-v2.Q5_K_S.gguf\"\n",
    "    },\n",
    "    2: {\n",
    "        \"id\": \"mradermacher/MN-LooseCannon-12B-v2-GGUF\",\n",
    "        \"file\": \"https://huggingface.co/mradermacher/MN-LooseCannon-12B-v2-GGUF/blob/main/MN-LooseCannon-12B-v2.Q6_K.gguf\"\n",
    "    },\n",
    "    3: {\n",
    "        \"id\": \"bartowski/Dans-PersonalityEngine-V1.1.0-12b-GGUF\",\n",
    "        \"file\": \"https://huggingface.co/bartowski/Dans-PersonalityEngine-V1.1.0-12b-GGUF/blob/main/Dans-PersonalityEngine-V1.1.0-12b-Q6_K.gguf\"\n",
    "    },\n",
    "    4: {\n",
    "        \"id\":\"mradermacher/Magnum-Picaro-0.7-v2-12b-i1-GGUF\",\n",
    "        \"file\":\"https://huggingface.co/mradermacher/Magnum-Picaro-0.7-v2-12b-i1-GGUF/blob/main/Magnum-Picaro-0.7-v2-12b.i1-Q6_K.gguf\"\n",
    "    }\n",
    "}\n",
    "\n",
    "PRESET = \"1\" #@param [1,2,3,4]\n",
    "\n",
    "MODEL = OPTIONS[int(PRESET)][\"file\"].replace(\"/blob/\", \"/resolve/\")\n",
    "\n",
    "!aria2c -x 10 -o model.gguf --summary-interval=5 --download-result=default --allow-overwrite=true --file-allocation=none $MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@LAUNCH!\n",
    "\n",
    "GPU_LAYERS = 80 #@param\n",
    "CONTEXT_SIZE = 8192 #@param\n",
    "\n",
    "!chmod +x ./koboldcpp_linux\n",
    "!./koboldcpp_linux model.gguf --noshift --usecublas 0 mmq --gpulayers $GPU_LAYERS --contextsize $CONTEXT_SIZE --quiet --remotetunnel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
